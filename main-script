#!/bin/sh
if [ "$1" == "stop" ] ; then exit; fi 

mkdir -p /var/spool/joboutputs
chmod ugo+rwxt /var/spool/joboutputs/

(
# Cloud Init should do this automatically but something has changed since cernvm3 -> cernvm4
ls -l /root/.ssh/authorized_keys
if [ ! -s /root/.ssh/authorized_keys ] ; then
  curl http://169.254.169.254/latest/meta-data/public-keys/0/openssh-key > /root/.ssh/authorized_keys
  echo >> /root/.ssh/authorized_keys
  ls -l /root/.ssh/authorized_keys
fi

# For the big 40GB+ logical partition
mkdir -p /scratch

# Find the largest unformatted partition on any device by trying to format them
sfdisk -sldu M | grep '^/dev/.*size=' | sed 's:\(/dev/[a-z]*[0-9]*\) .*size= *\([0-9]*\).*:\2 \1:' | sort -nr | (
while read size device
do
  mkfs -q -t ext4 $device
  if [ $? = 0 ] ; then
   # If we can make a new partition, then we use it
   date --utc +"%Y-%m-%d %H:%M:%S %Z user_data_script Created $device for /scratch"
   mount $device /scratch
   break
  fi
done
)

# fallocate is almost instantaneous on ext4
fallocate -l 3G /scratch/swapfile
chmod 0600 /scratch/swapfile
mkswap /scratch/swapfile
swapon /scratch/swapfile
sysctl vm.swappiness=1
mkdir -p /scratch/condor/
chown condor:condor /scratch/condor/

cat <<EOF >/tmp/x509proxy.pem
##user_data_option_x509_proxy##
EOF
chown root.root /tmp/x509proxy.pem
chmod 0400 /tmp/x509proxy.pem
openssl x509 -in /tmp/x509proxy.pem -text > /var/spool/joboutputs/x509proxy.cert.pem

. /root/mjf.sh
export job_id=`python -c "import urllib ; print urllib.urlopen('$JOBFEATURES/job_id').read().strip()"`
export wall_limit_secs=`python -c "import urllib ; print urllib.urlopen('$JOBFEATURES/wall_limit_secs').read().strip()"`

# Send a heartbeat every 5 minutes
(
while true
do
  echo `cut -f1-3 -d' ' /proc/loadavg` `cat /proc/uptime` >/var/spool/joboutputs/heartbeat
  date --utc +"%Y-%m-%d %H:%M:%S %Z Uploading heartbeat"
  /usr/bin/curl --max-time 30 --capath /etc/grid-security/certificates/ --cert /tmp/x509proxy.pem --cacert /tmp/x509proxy.pem --location --upload-file /var/spool/joboutputs/heartbeat '##user_data_joboutputs_url##/heartbeat'
  date --utc +"%Y-%m-%d %H:%M:%S %Z curl returns $?"
  sleep 300
done
) >/var/log/heartbeat.log 2>&1 &

# Enable config-egi.egi.eu
cat <<EOF >/etc/cvmfs/default.d/60-egi.conf
CVMFS_CONFIG_REPOSITORY=config-egi.egi.eu
EOF

# Apply the CernVM-FS configuration changes
cvmfs_config reload

# Remove docker command etc since we don't start docker
rpm --nodeps -e docker-cernvm

# Hard links to Condor log files are put here, so they survive Condor attempting to delete them
mkdir -p /scratch/joblogs
chmod ugo+wxt,u+r,go-r /scratch/joblogs
( 
while :
do
sleep 120
ln -f /scratch/pilot/$job_id/glide_*/log/*Log /scratch/joblogs/
done
) &

# Set up standard WLCG WN things
ln -s /cvmfs/grid.cern.ch/etc/grid-security/vomses /etc/vomses
ln -s /cvmfs/grid.cern.ch/etc/grid-security/vomsdir /etc/grid-security/vomsdir
ln -s /cvmfs/grid.cern.ch/umd-c7wn-latest/etc/profile.d/setup-c7-wn-example.sh /etc/profile.d/
echo "export JOB_ID=$job_id QUEUE=##user_data_machinetype## GLOBUS_LOCATION=/cvmfs/grid.cern.ch/umd-c7wn-latest/usr" >/etc/profile.d/pilot.sh

# Convert the generic X.509 proxy we have into a DUNE pilot proxy
# by adding VOMS ACs to X.509 proxy 
cp /tmp/x509proxy.pem /tmp/x509vomsproxy.pem
chmod 0600 /tmp/x509vomsproxy.pem
. /etc/profile.d/setup-c7-wn-example.sh
export X509_USER_PROXY=/tmp/x509vomsproxy.pem
voms-proxy-init -noregen -valid 168:0 -voms dune:/dune/Role=pilot
voms-proxy-info -file $X509_USER_PROXY

# Set up the pilot user which runs the pilot script
useradd pilot
mkdir -p /scratch/pilot/$job_id
curl https://raw.githubusercontent.com/glideinWMS/glideinwms/master/tools/manual_glidein_startup > manual_glidein_startup
chmod +x /scratch/pilot/$job_id/manual_glidein_startup
#
# Map Vac/Vcycle spaces to manual_glidein_startup parameters
# These can be discovered with commands like:
#   condor_status -pool gfactory-2.opensciencegrid.org -any -af ClientName ReqName | grep -i manchester
#
case "##user_data_space##" in
*.manchester.ac.uk)
  WMS_COLLECTOR=gfactory-2.opensciencegrid.org
  CLIENT_NAME=gpfrontend01-fnal-gov_gWMSFrontend.dune_cern
  REQ_NAME=UBoone_T2_UK_Manchester_ce02@gfactory_instance@OSG
  ;;
*)
  REQ_NAME=''
  ;;
esac

./manual_glidein_startup \
  --wms-collector=$WMS_COLLECTOR \
  --client-name=$CLIENT_NAME \
  --req-name=$REQ_NAME \
  --cmd-out-file=glidein_startup_wrapper \
  --glidein-startup=./glidein_startup.sh

#./manual_glidein_startup \
#  --wms-collector=gfactory-2.opensciencegrid.org \
#  --client-name=chtc2.main \
#  --req-name=OSG_US_WSU_GRID_ce2@gfactory_instance@OSG \
#  --cmd-out-file=glidein_startup_wrapper \
#  --glidein-startup=./glidein_startup.sh

cat <<EOF > /scratch/pilot/pilot.sh
cd /scratch/pilot/$job_id
export X509_USER_PROXY=/tmp/x509vomsproxy.pem
/scratch/pilot/$job_id/glidein_startup_wrapper < /dev/null \
1>/var/spool/joboutputs/glidein_startup_wrapper.stdout \
2>/var/spool/joboutputs/glidein_startup_wrapper.stderr
EOF
chmod +x /scratch/pilot/pilot.sh
chown -R pilot.pilot /scratch/pilot /tmp/x509vomsproxy.pem

if [ "$REQ_NAME" != "" ] ; then
  # Run the pilot script which in turn runs glidein_startup.sh
  /usr/bin/sudo -i -n -u pilot /scratch/pilot/pilot.sh 2>&1

  # Always try to make simple HTCondor shutdown messages
  if [ ! -s /scratch/joblogs/StartdHistoryLog ] ; then
    echo '300 No HTCondor job to run' > /var/spool/joboutputs/shutdown_message
  else
    echo '200 Success' > /var/spool/joboutputs/shutdown_message
  fi
else
  # No hardcoded mapping of space to glideinWMS entry in the case...esac above
  echo "400 No glideinWMS entry for ##user_data_space##" > /var/spool/joboutputs/shutdown_message
fi

# Time to upload and shutdown
cd /var/spool/joboutputs
cp -f /var/log/cloud-init*.log \
      /var/log/boot.log \
      /var/log/messages \
      /scratch/joblogs/* \
      .
for i in * 
do 
  curl --capath /etc/grid-security/certificates/ --cert /tmp/x509proxy.pem --cacert /tmp/x509proxy.pem --location --upload-file "$i" '##user_data_joboutputs_url##/'
  curl --capath /etc/grid-security/certificates/ --cert /tmp/x509proxy.pem --cacert /tmp/x509proxy.pem --location --upload-file "$i" "https://depo.gridpp.ac.uk/hosts/##user_data_space##/##user_data_machinetype##/##user_data_machine_hostname##/$job_id/"
done

# Try normal shutdown
shutdown -h now
sleep 60
# Otherwise instant shutdown
echo o > /proc/sysrq-trigger

) >/var/spool/joboutputs/shellscript.log 2>&1 &
